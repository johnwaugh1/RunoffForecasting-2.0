{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa5459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b43c0dc",
   "metadata": {},
   "source": [
    "Define Paths and Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94441880",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"../data/processed\")\n",
    "models_dir = Path(\"../models\")\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "figures_dir = results_dir / \"figures\"\n",
    "figures_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e517c",
   "metadata": {},
   "source": [
    "Define Helper Functions to Recreate the Featured Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8947ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aligned_dataframe(nwm_df, usgs_df):\n",
    "    \"\"\"Aligns NWM forecasts with USGS observations and calculates error.\"\"\"\n",
    "    nwm_df = nwm_df.sort_values(by='model_output_valid_time')\n",
    "    usgs_df = usgs_df.sort_index()\n",
    "    aligned_df = pd.merge_asof(\n",
    "        left=nwm_df, right=usgs_df,\n",
    "        left_on='model_output_valid_time', right_index=True,\n",
    "        direction='nearest', tolerance=pd.Timedelta(minutes=30)\n",
    "    )\n",
    "    aligned_df.dropna(subset=['USGSFlowValue'], inplace=True)\n",
    "    aligned_df = aligned_df.rename(columns={\n",
    "        'streamflow_value': 'NWM_streamflow', 'USGSFlowValue': 'USGS_streamflow'\n",
    "    })\n",
    "    return aligned_df\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Creates the target variable and input features.\"\"\"\n",
    "    df['error'] = df['NWM_streamflow'] - df['USGS_streamflow']\n",
    "    valid_time = df['model_output_valid_time']\n",
    "    df['month'] = valid_time.dt.month\n",
    "    df['day_of_year'] = valid_time.dt.dayofyear\n",
    "    df['hour'] = valid_time.dt.hour\n",
    "    feature_cols = [\n",
    "        'error', 'NWM_streamflow', 'USGS_streamflow', # Also include USGS for later\n",
    "        'lead_time', 'month', 'day_of_year', 'hour'\n",
    "    ]\n",
    "    df_featured = df[['model_output_valid_time'] + feature_cols].set_index('model_output_valid_time')\n",
    "    return df_featured\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373add0",
   "metadata": {},
   "source": [
    "Load Data and Recreate Featured Dataframe for each Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37dd7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = {}\n",
    "for station_name in ['station1', 'station2']:\n",
    "    # Load the raw component data\n",
    "    nwm_df = pd.read_parquet(data_dir / f\"{station_name}_nwm.parquet\")\n",
    "    usgs_df = pd.read_parquet(data_dir / f\"{station_name}_usgs.parquet\")\n",
    "    \n",
    "    # Ensure datetime types match for merging\n",
    "    if nwm_df['model_output_valid_time'].dt.tz is None:\n",
    "        nwm_df['model_output_valid_time'] = nwm_df['model_output_valid_time'].dt.tz_localize('UTC')\n",
    "    # Recreate the aligned and featured dataframe\n",
    "    aligned_df = create_aligned_dataframe(nwm_df, usgs_df)\n",
    "    featured_df = create_features(aligned_df)\n",
    "\n",
    "    # Load the sequenced test data\n",
    "    data_for_modeling = np.load(data_dir / f'{station_name}_processed_for_modeling.npz')\n",
    "    # Load the scaler\n",
    "    with open(data_dir / f'scaler_{station_name}.pkl', 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    \n",
    "    station_data[station_name] = {\n",
    "        'X_test': data_for_modeling['X_test'],\n",
    "        'y_test_scaled': data_for_modeling['y_test'],\n",
    "        'scaler': scaler,\n",
    "        'original_featured_df': featured_df # This now correctly holds the data we need\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f0ae7",
   "metadata": {},
   "source": [
    "Define the Metrics Calculation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba37065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. All data, models, and scalers are ready.\n"
     ]
    }
   ],
   "source": [
    "def calculate_metrics(observed, forecasted):\n",
    "    \"\"\"Calculates CC, RMSE, PBIAS, and NSE.\"\"\"\n",
    "    observed = np.array(observed)\n",
    "    forecasted = np.array(forecasted)\n",
    "    \n",
    "    # Coefficient of correlation (CC)\n",
    "    cc = np.corrcoef(observed, forecasted)[0, 1]\n",
    "    \n",
    "    # Root mean square error (RMSE)\n",
    "    rmse = np.sqrt(np.mean((forecasted - observed) ** 2))\n",
    "    \n",
    "    # Percent bias (PBIAS)\n",
    "    pbias = 100 * np.sum(forecasted - observed) / np.sum(observed)\n",
    "    \n",
    "    # Nash-Sutcliffe Efficiency (NSE)\n",
    "    nse = 1 - (np.sum((forecasted - observed) ** 2) / np.sum((observed - np.mean(observed)) ** 2))\n",
    "    \n",
    "    return {'CC': cc, 'RMSE': rmse, 'PBIAS': pbias, 'NSE': nse}\n",
    "\n",
    "print(\"Setup complete. All data, models, and scalers are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8912e",
   "metadata": {},
   "source": [
    "Loop through each model, make predictions, and calculate the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b4c4c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "///// Evaluating models for station1 /////\n",
      "============================================================\n",
      "\n",
      "--- Evaluating LSTM model ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=..\\models\\station1_lstm_model.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m model ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstation_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_model.keras\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 1. Make predictions (these are the scaled errors)\u001b[39;00m\n\u001b[32m     24\u001b[39m predicted_error_scaled = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\John Waugh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:200\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath, custom_objects=custom_objects, \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m\n\u001b[32m    198\u001b[39m     )\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: File not found: filepath=..\\models\\station1_lstm_model.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "LOOKBACK = 24 # Must be the same as in the preprocessing step\n",
    "\n",
    "for station_name in ['station1', 'station2']:\n",
    "    print(f\"\\n{'='*60}\\n///// Evaluating models for {station_name} /////\\n{'='*60}\")\n",
    "    all_results[station_name] = {}\n",
    "    \n",
    "    # Get the data for the current station\n",
    "    data = station_data[station_name]\n",
    "    X_test = data['X_test']\n",
    "    scaler = data['scaler']\n",
    "    \n",
    "    # We need the original test dataframe to get unscaled values and lead times\n",
    "    test_start_date = '2022-10-01 00:00:00'\n",
    "    original_test_df = data['original_featured_df'].loc[test_start_date:].iloc[LOOKBACK:]\n",
    "\n",
    "    for model_name in ['lstm', 'gru', 'transformer']:\n",
    "        print(f\"\\n--- Evaluating {model_name.upper()} model ---\")\n",
    "        \n",
    "        # Load the trained model\n",
    "        model = keras.models.load_model(models_dir / f\"{station_name}_{model_name}_model.keras\")\n",
    "        \n",
    "        # 1. Make predictions (these are the scaled errors)\n",
    "        predicted_error_scaled = model.predict(X_test)\n",
    "        \n",
    "        # 2. Inverse scale the predictions\n",
    "        # Create a dummy array with the same shape as the input to the scaler\n",
    "        dummy_array = np.zeros((len(predicted_error_scaled), X_test.shape[2]))\n",
    "        dummy_array[:, 0] = predicted_error_scaled.ravel() # Put predictions in the first column ('error')\n",
    "        predicted_error_unscaled = scaler.inverse_transform(dummy_array)[:, 0]\n",
    "        \n",
    "        # 3. Create a results DataFrame\n",
    "        results_df = original_test_df.copy()\n",
    "        results_df['predicted_error'] = predicted_error_unscaled\n",
    "        \n",
    "        # 4. Calculate the corrected forecast\n",
    "        # Corrected_Forecast = NWM_streamflow - predicted_error\n",
    "        # Note the minus sign, because our error = NWM - USGS\n",
    "        results_df['Corrected_Forecast'] = results_df['NWM_streamflow'] - results_df['predicted_error']\n",
    "\n",
    "        # 5. Calculate metrics for each lead time\n",
    "        metrics_by_lead_time = []\n",
    "        for lead_time, group in results_df.groupby('lead_time'):\n",
    "            if len(group) < 2: continue # Need at least 2 points to calculate correlation\n",
    "                \n",
    "            # Baseline metrics (Original NWM vs. Observed)\n",
    "            baseline_metrics = calculate_metrics(group['USGS_streamflow'], group['NWM_streamflow'])\n",
    "            baseline_metrics['lead_time'] = lead_time\n",
    "            baseline_metrics['type'] = 'NWM (Baseline)'\n",
    "            \n",
    "            # Corrected forecast metrics (Our Model vs. Observed)\n",
    "            corrected_metrics = calculate_metrics(group['USGS_streamflow'], group['Corrected_Forecast'])\n",
    "            corrected_metrics['lead_time'] = lead_time\n",
    "            corrected_metrics['type'] = f'Corrected ({model_name.upper()})'\n",
    "            \n",
    "            metrics_by_lead_time.extend([baseline_metrics, corrected_metrics])\n",
    "            \n",
    "        metrics_df = pd.DataFrame(metrics_by_lead_time)\n",
    "        \n",
    "        # Store results for plotting\n",
    "        all_results[station_name][model_name] = {'results_df': results_df, 'metrics_df': metrics_df}\n",
    "        print(f\"Evaluation complete for {model_name.upper()}.\")\n",
    "\n",
    "# Save the final results dictionary\n",
    "with open(results_dir / 'all_evaluation_results.pkl', 'wb') as f:\n",
    "    pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd13864",
   "metadata": {},
   "source": [
    "Visualization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4316a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for station_name, models in all_results.items():\n",
    "    for model_name, data in models.items():\n",
    "        results_df = data['results_df']\n",
    "        metrics_df = data['metrics_df']\n",
    "        \n",
    "        # --- 1. Runoff Box Plot ---\n",
    "        plt.figure(figsize=(18, 8))\n",
    "        \n",
    "        # Prepare data for boxplot\n",
    "        plot_data = results_df[['lead_time', 'USGS_streamflow', 'NWM_streamflow', 'Corrected_Forecast']]\n",
    "        plot_data = plot_data.melt(id_vars='lead_time', var_name='Type', value_name='Flow')\n",
    "        plot_data.rename(columns={'Type': 'Forecast Type'}, inplace=True)\n",
    "\n",
    "        sns.boxplot(data=plot_data, x='lead_time', y='Flow', hue='Forecast Type')\n",
    "        plt.title(f'{station_name} - {model_name.upper()}: Runoff Comparison by Lead Time', fontsize=16)\n",
    "        plt.xlabel('Lead Time (hours)')\n",
    "        plt.ylabel('Streamflow (mÂ³/s)')\n",
    "        plt.legend(title='Forecast Type')\n",
    "        plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figures_dir / f\"{station_name}_{model_name}_runoff_boxplot.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # --- 2. Metrics Comparison Plots ---\n",
    "        for metric in ['CC', 'RMSE', 'PBIAS', 'NSE']:\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            sns.lineplot(data=metrics_df, x='lead_time', y=metric, hue='type', marker='o', style='type')\n",
    "            plt.title(f'{station_name} - {model_name.upper()}: {metric} vs. Lead Time', fontsize=16)\n",
    "            plt.xlabel('Lead Time (hours)')\n",
    "            plt.ylabel(metric)\n",
    "            plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "            # For NSE, add a zero line for reference\n",
    "            if metric == 'NSE':\n",
    "                plt.axhline(0, color='red', linestyle='--', label='NSE = 0 (Baseline)')\n",
    "            plt.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(figures_dir / f\"{station_name}_{model_name}_metric_{metric}.png\")\n",
    "            plt.show()\n",
    "\n",
    "print(\"\\nAll visualizations are complete and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
